# Word Embeddings

Layman's tutorial to word embeddings, explained in detail at: https://algobeans.com/2021/10/29/mapping-global-cuisine-with-word-embeddings

<p>
Word Embeddings generate similarity scores to deduce how distinct each word is relative to other words. Using these similarity scores, we can plot the words on a map, with more similar words being closer to each other. For example, the following is a word map generated by shortlisting the top 17 words most similar to Flatbread:
    <br>
<img src="https://annalyzin.files.wordpress.com/2021/10/map1.png?w=300">
<img src="https://annalyzin.files.wordpress.com/2021/10/map2.png?w=300">
</p>

The code used can be found here: https://github.com/algobeans/Word-Embeddings/blob/main/word-embeddings.ipynb

<p>
A simplified example of the word embedding algorithm, based on two sentences and two target words:
  <br>
<img src="https://annalyzin.files.wordpress.com/2021/10/embedding-example-1.gif?w=550&zoom=2">
</p>


For more details, see the full post at: https://algobeans.com/2021/10/29/mapping-global-cuisine-with-word-embeddings



