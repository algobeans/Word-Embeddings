# Word Embeddings

Layman's tutorial to word embeddings, explained in detail at: https://algobeans.com/xxx

<p>
Word Embeddings generates similarity scores to deduce how far each word is relative to other words, thereby allowing us to spread words out on a map and examine how they relate to each other. The following is a map obtained by shortlisting the top 17 words closest to Flatbread:
    <br>
<img src="https://annalyzin.files.wordpress.com/2021/10/map1.png?w=768">
  <br>
<img src="https://annalyzin.files.wordpress.com/2021/10/map2.png?w=768">
</p>

<p>
A simplified example of the word embedding algorithm, based on two sentences and two target words:
  <br>
<img src="https://annalyzin.files.wordpress.com/2021/10/embedding-example-1.gif?w=619&zoom=2">
</p>




Layman's tutorial to word embeddings, explained in detail at: https://algobeans.com/xxx


